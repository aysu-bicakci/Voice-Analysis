{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERİLEN SES KAYITLARININ MFCC ÖZELLİKLERİNİN ÇIKARILMASI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ses dosyalarınızı kaydettiğiniz klasör\n",
    "ses_dosyasi_klasoru = \"ses_verileri\"\n",
    "\n",
    "def ozellik_cikarma(file_path):\n",
    "    # Ses dosyasını yükleme\n",
    "    y, sr = librosa.load(file_path, duration=5)  # 5 saniye sınırlaması\n",
    "    # MFCC özelliklerini çıkarma\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    # Ortalama alarak sabit boyutlu bir vektör elde etme\n",
    "    return np.mean(mfcc, axis=1)\n",
    "\n",
    "# Tüm dosyalar için özellik çıkarma\n",
    "veri = []\n",
    "etiketler = []\n",
    "\n",
    "for file in os.listdir(ses_dosyasi_klasoru):\n",
    "    if file.endswith('.wav'):\n",
    "        file_path = os.path.join(ses_dosyasi_klasoru, file)\n",
    "        features = ozellik_cikarma(file_path)\n",
    "        veri.append(features)\n",
    "        etiketler.append(file.split('.')[0])  # Dosya adını etiket olarak kullanma\n",
    "\n",
    "veri = np.array(veri)\n",
    "etiketler = np.array(etiketler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELİ EĞİTME KAYDI VERİLEN KİSİNİN KİM OLDUGUNU BULMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla eğitildi ve kaydedildi.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Tahmin edilen kişi: aysu\n",
      "Test seti üzerindeki doğruluk(accuracy): 0.78\n",
      "Test seti üzerindeki F1 skoru: 0.81\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        aysu       0.80      1.00      0.89         4\n",
      "      dilara       1.00      0.50      0.67         2\n",
      "       guzel       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.88      0.78      0.82         9\n",
      "   macro avg       0.93      0.72      0.79         9\n",
      "weighted avg       0.91      0.78      0.81         9\n",
      "\n",
      "Unique classes in y_test: [1 2 3]\n",
      "Classes from LabelEncoder: ['aysu' 'dilara' 'guzel' 'kadero']\n",
      "Karışıklık Matrisi:\n",
      "[[0 0 0 0]\n",
      " [0 4 0 0]\n",
      " [1 0 1 0]\n",
      " [0 1 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2687: UserWarning: labels size, 3, does not match size of target_names, 4\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import librosa \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "import os\n",
    "\n",
    "# Özellik çıkarma fonksiyonu\n",
    "def ozellik_cikarma(file_path):\n",
    "    y, sr = librosa.load(file_path, duration=5)  # Ses dosyasını yükleme\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # MFCC çıkarma\n",
    "    return np.mean(mfcc, axis=1)  # Ortalama ile sabit boyutlu vektör\n",
    "\n",
    "# Veriyi yükleme\n",
    "def veri_yukle(ses_klasoru):\n",
    "    veri = []\n",
    "    etiketler = []\n",
    "    for file in os.listdir(ses_klasoru):\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(ses_klasoru, file)\n",
    "            features = ozellik_cikarma(file_path)\n",
    "            veri.append(features)\n",
    "            etiketler.append(file.split('_')[0])  # Kişi adı dosya adından alınır\n",
    "    return np.array(veri), np.array(etiketler)\n",
    "\n",
    "# Ses dosyalarının bulunduğu klasör\n",
    "ses_klasoru = \"ses_verileri\"\n",
    "X, y = veri_yukle(ses_klasoru)\n",
    "\n",
    "# Etiketleri sayısal forma dönüştürme\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Veriyi eğitim ve test olarak ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "# Veri türlerini kontrol etme ve düzeltme\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Model oluşturma\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Giriş: Özellik sayısı\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')  # Çıkış: Kişi sayısı\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Modeli kaydetme\n",
    "model.save(\"ses_tanima_modeli.keras\")\n",
    "print(\"Model başarıyla eğitildi ve kaydedildi.\")\n",
    "\n",
    "# Yeni ses dosyasını tahmin etme\n",
    "def ses_tahmin_et(model_path, file_path, label_encoder):\n",
    "    model = load_model(model_path , compile=False)\n",
    "    features = ozellik_cikarma(file_path).reshape(1, -1)  # Model girişine uygun boyut\n",
    "    tahmin = model.predict(features)\n",
    "    tahmin_kisi = label_encoder.inverse_transform([np.argmax(tahmin)])\n",
    "    return tahmin_kisi[0]\n",
    "\n",
    "# Modelin doğruluğunu ve F1 skorunu değerlendirme\n",
    "y_pred = model.predict(X_test)  # Test verisi üzerindeki tahminler\n",
    "y_pred_class = np.argmax(y_pred, axis=1)  # Sınıf tahminlerini al (softmax sonucu)\n",
    "\n",
    "# F1 skoru hesaplama\n",
    "f1 = f1_score(y_test, y_pred_class, average='weighted')  # weighted: Sınıf dengesizliğini göz önünde bulundurur\n",
    "\n",
    "# Test için bir ses dosyası tahmini\n",
    "test_ses_dosyasi = \"ses_verileri/aysu_01.wav\"  # Test edilecek dosya\n",
    "tahmin = ses_tahmin_et(\"ses_tanima_modeli.keras\", test_ses_dosyasi, le)\n",
    "print(f\"Tahmin edilen kişi: {tahmin}\")\n",
    "\n",
    "# Modelin doğruluğunu değerlendirme\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test seti üzerindeki doğruluk(accuracy): {accuracy:.2f}\")\n",
    "print(f\"Test seti üzerindeki F1 skoru: {f1:.2f}\")\n",
    "\n",
    "# Sınıflandırma raporunu yazdırma\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, y_pred_class, target_names=le.classes_, labels=np.unique(y_test)))\n",
    "\n",
    "print(\"Unique classes in y_test:\", np.unique(y_test))\n",
    "print(\"Classes from LabelEncoder:\", le.classes_)\n",
    "\n",
    "# Karışıklık matrisini yazdırma\n",
    "print(\"Karışıklık Matrisi:\")\n",
    "print(confusion_matrix(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KONUŞAN KİSİNİN KİM OLDUGUNU ANLIK OLARAK BULMAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kayıt başlıyor...\n",
      "Kayıt tamamlandı.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Mikrofondan kaydedilen sesin tahmini: aysu\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import wave\n",
    "\n",
    "def ses_kaydet(output_file, sure=5, fs=44100):\n",
    "    print(\"Kayıt başlıyor...\")\n",
    "    kayit = sd.rec(int(sure * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "    sd.wait()  # Kayıt tamamlanana kadar bekle\n",
    "    print(\"Kayıt tamamlandı.\")\n",
    "    \n",
    "    # Kaydı wav formatında kaydet\n",
    "    with wave.open(output_file, 'wb') as wf:\n",
    "        wf.setnchannels(1)  # Mono kanal\n",
    "        wf.setsampwidth(2)  # 16-bit\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(kayit.tobytes())\n",
    "\n",
    "# Mikrofondan kayıt yap ve tahmini gerçekleştir\n",
    "kayıt_dosyasi = \"mikrofon_kayit.wav\"\n",
    "ses_kaydet(kayıt_dosyasi)\n",
    "\n",
    "tahmin = ses_tahmin_et(\"ses_tanima_modeli.keras\", kayıt_dosyasi, le)\n",
    "print(f\"Mikrofondan kaydedilen sesin tahmini: {tahmin}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXTE ÇEVİRME VE KELİME SAYISI BULMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin: sevdiğin birinin beni anlamadığını hissetmek çok acı verici cevaplar\n",
      "Kelime Sayısı: 9\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Tanıyıcıyı başlatın\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Ses dosyasını tanıyın\n",
    "audio_file = \"mikrofon_kayit.wav\"\n",
    "\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    audio = recognizer.record(source)\n",
    "\n",
    "# Türkçe ses dosyasını metne çevirin\n",
    "try:\n",
    "    text = recognizer.recognize_google(audio, language=\"tr-TR\")\n",
    "    print(\"Metin:\",text)\n",
    "    \n",
    "    # Metin üzerinde kelime sayısı hesaplama\n",
    "    words =text.split()\n",
    "    word_count = len(words)\n",
    "    print(f\"Kelime Sayısı: {word_count}\")\n",
    "    \n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech-to-Text, sesi anlayamadı.\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Google Speech-to-Text servisi kullanılamıyor: {e}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texte Çevirme, Duygu ve Konu Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForSequenceClassification: ['model.decoder.version', 'model.encoder.version']\n",
      "- This IS expected if you are initializing TFBartForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "c:\\Users\\HP\\Downloads\\install\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript:\n",
      "sevdiğin birinin beni anlamadığını hissetmek çok acı verici cevaplar\n",
      "\n",
      "Kelime Sayısı: 9\n",
      "\n",
      "Duygu Analizi:\n",
      "sadness: %99.13\n",
      "joy: %0.58\n",
      "love: %0.11\n",
      "anger: %0.11\n",
      "fear: %0.05\n",
      "surprise: %0.02\n",
      "\n",
      "Konu Analizi:\n",
      "En uygun konu: feelings (%73.42)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# MP3'ten WAV'a dönüştürme fonksiyonu\n",
    "def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "    audio.export(wav_file_path, format=\"wav\")\n",
    "\n",
    "# Ses dosyasını metne çevirme fonksiyonu\n",
    "def transcribe_audio(audio_file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        transcript = recognizer.recognize_google(audio, language=\"tr-TR\")\n",
    "        return transcript\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results; {e}\"\n",
    "\n",
    "# Metni Türkçeden İngilizceye çevirme fonksiyonu\n",
    "def translate_to_english(text):\n",
    "    translation = GoogleTranslator(source='tr', target='en').translate(text)\n",
    "    return translation\n",
    "\n",
    "# Zero-shot sınıflandırma için transformer modeli\n",
    "topic_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "sentiment_analyzer = pipeline(\"text-classification\", model=\"bhadresh-savani/bert-base-uncased-emotion\", return_all_scores=True)\n",
    "\n",
    "# Duygu Analizi Fonksiyonu\n",
    "def analyze_emotion(text):\n",
    "    results = sentiment_analyzer(text, truncation=True)\n",
    "    emotions = {result['label']: result['score'] for result in results[0]}\n",
    "    total = sum(emotions.values())\n",
    "    percentages = {emotion: (score / total) * 100 for emotion, score in emotions.items()}\n",
    "    return percentages\n",
    "\n",
    "# Konu Analizi Fonksiyonu\n",
    "def analyze_topic(text):\n",
    "    topics = [\"sport\", \"technology\", \"health\", \"art\", \"weather\", \"feelings\"]\n",
    "    result = topic_classifier(text, candidate_labels=topics)\n",
    "    return result['labels'][0], result['scores'][0]\n",
    "\n",
    "# Ana kod\n",
    "if __name__ == \"__main__\":\n",
    "    wav_file_path = \"mikrofon_kayit.wav\"  # Path to the converted WAV file\n",
    "\n",
    "    # Ses dosyasını yazıya çevir\n",
    "    transcript = transcribe_audio(wav_file_path)\n",
    "\n",
    "    print(\"\\nTranscript:\")\n",
    "    print(transcript)\n",
    "    \n",
    "    words =transcript.split()\n",
    "    word_count = len(words)\n",
    "    print(f\"\\nKelime Sayısı: {word_count}\")\n",
    "\n",
    "    # İngilizceye çevir\n",
    "    translated_text = translate_to_english(transcript)\n",
    "   \n",
    "    # Duygu Analizi\n",
    "    print(\"\\nDuygu Analizi:\")\n",
    "    if translated_text:\n",
    "        emotion_percentages = analyze_emotion(translated_text)\n",
    "        for emotion, percentage in emotion_percentages.items():\n",
    "            print(f\"{emotion}: %{percentage:.2f}\")\n",
    "    else:\n",
    "        print(\"Duygu analizi yapılamadı.\")\n",
    "\n",
    "    # Konu Analizi\n",
    "    print(\"\\nKonu Analizi:\")\n",
    "    topic, score = analyze_topic(translated_text)\n",
    "    print(f\"En uygun konu: {topic} (%{score*100:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
